{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import fastparquet\n",
    "import warnings\n",
    "import geopy\n",
    "from geopy.point import Point\n",
    "import time\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_fig_to_html(list_of_figs):\n",
    "    for fig in list_of_figs:\n",
    "        with open(\"reports/report_draft_june19.html\",'a') as f:\n",
    "            f.write(fig.to_html(full_html=False, include_plotlyjs='cdn'))\n",
    "\n",
    "\n",
    "property_tax_map = {\n",
    "    'AL' : 0.0037,\n",
    "    'AK' : 0.0098,\n",
    "    'AZ' : 0.0060,\n",
    "    'AK' : 0.0061,\n",
    "    'CA' : 0.0070,\n",
    "    'CO' : 0.0052,\n",
    "    'CT' : 0.0173,\n",
    "    'DE' : 0.0059,\n",
    "    'FL' : 0.0086,\n",
    "    'GA' : 0.0087,\n",
    "    'HI' : 0.0031,\n",
    "    'ID' : 0.0065,\n",
    "    'IL' : 0.0197,\n",
    "    'IN' : 0.0081,\n",
    "    'IA' : 0.0143,\n",
    "    'KS' : 0.0128,\n",
    "    'KY' : 0.0078,\n",
    "    'LA' : 0.0051,\n",
    "    'ME' : 0.0120,\n",
    "    'MD' : 0.0101,\n",
    "    'MA' : 0.0108,\n",
    "    'MI' : 0.0131,\n",
    "    'MN' : 0.0105,\n",
    "    'MS' : 0.0063,\n",
    "    'MO' : 0.0096,\n",
    "    'MT' : 0.0074,\n",
    "    'NE' : 0.0154,\n",
    "    'NV' : 0.0056,\n",
    "    'NH' : 0.0189,\n",
    "    'NJ' : 0.0213,\n",
    "    'NM' : 0.0059,\n",
    "    'NY' : 0.0130,\n",
    "    'NC' : 0.0078,\n",
    "    'ND' : 0.0088,\n",
    "    'OH' : 0.0152,\n",
    "    'OK' : 0.0083,\n",
    "    'OR' : 0.0091,\n",
    "    'PA' : 0.0143,\n",
    "    'RI' : 0.0137,\n",
    "    'SC' : 0.0053,\n",
    "    'SD' : 0.0114,\n",
    "    'TN' : 0.0063,\n",
    "    'TX' : 0.0160,\n",
    "    'UT' : 0.0056,\n",
    "    'VT' : 0.0176,\n",
    "    'VA' : 0.0084,\n",
    "    'WA' : 0.0084,\n",
    "    'WV' : 0.0053,\n",
    "    'WI' : 0.0153,\n",
    "    'WY' : 0.0051,\n",
    "    'DC' : 0.0058\n",
    "}\n",
    "\n",
    "def calculate_monthly_maintenance(home_value):\n",
    "    monthly_maintenance = home_value/100/12\n",
    "    return monthly_maintenance\n",
    "\n",
    "def calculate_monthly_taxes(home_value, state_id, property_tax_map=property_tax_map):\n",
    "    tax_rate = property_tax_map.get(state_id)\n",
    "    monthly_tax = home_value*tax_rate/12\n",
    "    return monthly_tax\n",
    "\n",
    "def calculate_mortgage(home_value, interest_rate, num_years, down_payment_pct=0):\n",
    "    if home_value is None:\n",
    "        return None\n",
    "    \n",
    "    per_payment_interest = 0\n",
    "    loan_value = 0\n",
    "\n",
    "\n",
    "    if down_payment_pct >= 1:\n",
    "        down_payment = down_payment_pct/100 * home_value\n",
    "        loan_value = home_value - down_payment\n",
    "    else:\n",
    "        down_payment = down_payment_pct * home_value\n",
    "        loan_value = home_value - down_payment\n",
    "    \n",
    "    if loan_value/home_value < 0.80: \n",
    "        # insert pmi calc here\n",
    "        pmi = 0.01  # using near average value here\n",
    "        pmi_cost = 0.0007*home_value    # shot in the dark after interpolating nerdwallet calculator\n",
    "        if interest_rate >= 1:\n",
    "            per_payment_interest = interest_rate/100/12\n",
    "        else:\n",
    "            per_payment_interest = interest_rate/12\n",
    "        num_months = num_years*12\n",
    "        mortgage = loan_value*(per_payment_interest*(1+per_payment_interest)**num_months)/((1+per_payment_interest)**num_months-1) + pmi_cost\n",
    "\n",
    "        mortgage = np.round(mortgage, 2)\n",
    "        return mortgage\n",
    "    else:\n",
    "        if interest_rate >= 1:\n",
    "            per_payment_interest = interest_rate/100/12\n",
    "        else:\n",
    "            per_payment_interest = interest_rate/12\n",
    "        num_months = num_years*12\n",
    "        mortgage = loan_value*(per_payment_interest*(1+per_payment_interest)**num_months)/((1+per_payment_interest)**num_months-1)\n",
    "\n",
    "        mortgage = np.round(mortgage, 2)\n",
    "        return mortgage\n",
    "\n",
    "def calculate_roi(airbnb_daily_price, occupancy_rate, monthly_mortgage, monthly_maintenence=0, monthly_taxes=0):\n",
    "    gross_rev = airbnb_daily_price * occupancy_rate * 365/12\n",
    "    net_rev = gross_rev - monthly_maintenence - monthly_taxes\n",
    "    profit = net_rev - monthly_mortgage\n",
    "    roi = profit/monthly_mortgage\n",
    "    roi = roi\n",
    "    return roi\n",
    "\n",
    "def set_location_desc(lat,long):\n",
    "    from geopy.geocoders import Nominatim\n",
    "    geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "    lat = str(lat)\n",
    "    long = str(long)\n",
    "    location = geolocator.reverse(lat+\",\"+long)\n",
    "    address = location.raw['address']\n",
    "    city = address.get('city', '')\n",
    "    state = address.get('state', '')\n",
    "    country = address.get('country')\n",
    "    country_code = address.get('country_code')\n",
    "    zipcode = address.get('postcode', '')\n",
    "    return city, state, country, country_code, zipcode\n",
    "\n",
    "def set_city(lat, long):\n",
    "    from geopy.geocoders import Nominatim\n",
    "    geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "    #start_time = time.time()\n",
    "    lat = str(lat)\n",
    "    #print(\"---Latitude casted to string at %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    long = str(long)\n",
    "    #print(\"---Longitude casted at %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    location = geolocator.reverse(lat+\",\"+long)\n",
    "    #print(\"---Get location json from geopy at %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    address = location.raw['address']\n",
    "    #print(\"---Get address json at %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    city = address.get('city', '')\n",
    "    #print(\"---Get city value at %s seconds ---\" % (time.time() - start_time))\n",
    "    return city\n",
    "\n",
    "def set_state(lat, long):\n",
    "    from geopy.geocoders import Nominatim\n",
    "    geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "    lat = str(lat)\n",
    "    long = str(long)\n",
    "    location = geolocator.reverse(Point(lat,long))\n",
    "    address = location.raw['address']\n",
    "    state = address.get('state', '')\n",
    "    return state\n",
    "\n",
    "def set_country(lat, long):\n",
    "    from geopy.geocoders import Nominatim\n",
    "    geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "    lat = str(lat)\n",
    "    long = str(long)\n",
    "    location = geolocator.reverse(Point(lat,long))\n",
    "    address = location.raw['address']\n",
    "    country = address.get('country')\n",
    "    return country\n",
    "\n",
    "def set_country_code(lat, long):\n",
    "    from geopy.geocoders import Nominatim\n",
    "    geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "    lat = str(lat)\n",
    "    long = str(long)\n",
    "    location = geolocator.reverse(lat+\",\"+long)\n",
    "    address = location.raw['address']\n",
    "    country_code = address.get('country_code')\n",
    "    return country_code\n",
    "\n",
    "def set_zipcode(lat, long):\n",
    "    from geopy.geocoders import Nominatim\n",
    "    geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "    lat = str(lat)\n",
    "    long = str(long)\n",
    "    location = geolocator.reverse(Point(lat,long))\n",
    "    address = location.raw['address']\n",
    "    zipcode = address.get('postcode', '')\n",
    "    return zipcode\n",
    "\n",
    "def set_interpolated_state(top_lat,bottom_lat,left_long,right_long):\n",
    "    lat = (top_lat+bottom_lat)/2\n",
    "    long = (left_long+right_long)/2\n",
    "    state = set_state(lat, long)\n",
    "    return state\n",
    "\n",
    "\n",
    "def set_avg_home_val_w_city(home_values, city, state, num_beds):\n",
    "    if num_beds <= 5:\n",
    "        desired_row = home_values[(home_values['RegionName'] == city) & (home_values['State'] == state) & (home_values['num_beds'] == num_beds)]\n",
    "        avg_value = desired_row['2022-04-30']\n",
    "        if len(avg_value) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            return avg_value.iloc[0]\n",
    "    else:\n",
    "        desired_row = home_values[(home_values['RegionName'] == city) & (home_values['State'] == state) & (home_values['num_beds'] == 5)]\n",
    "        avg_value = desired_row['2022-04-30']\n",
    "        if len(avg_value) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            return avg_value.iloc[0]*num_beds/5  # <-- improve this with linear regression later on\n",
    "\n",
    "def set_avg_home_val_w_zip(home_values, zipcode, num_beds):\n",
    "    if num_beds <= 5:\n",
    "        desired_row = home_values[(home_values['RegionName'] == zipcode) & (home_values['num_beds'] == num_beds)]\n",
    "        avg_value = desired_row['4/30/2022']\n",
    "        if avg_value.empty:\n",
    "            return None\n",
    "        else:\n",
    "            return avg_value.iloc[0]\n",
    "    else:\n",
    "        desired_row = home_values[(home_values['RegionName'] == zipcode) & (home_values['num_beds'] == 5)]\n",
    "        avg_value = desired_row['4/30/2022']\n",
    "        if avg_value.empty:\n",
    "            return None\n",
    "        else:\n",
    "            return avg_value.iloc[0]*num_beds/5  # <-- improve this with linear regression later on\n",
    "\n",
    "\n",
    "def list_options_for_dash(df_series):\n",
    "    options = []\n",
    "    value = 0\n",
    "    for i in df_series:\n",
    "        if value == 0:\n",
    "            value = i\n",
    "        town = {'label':i, 'value':i}\n",
    "        dict_copy = town.copy()\n",
    "        options.append(dict_copy)\n",
    "    return options, value\n",
    "\n",
    "def med_price_occ_by_guests(df, location: str):\n",
    "    df_guests = df.groupby(['guest_no'])['median_total_price'].median().reset_index()\n",
    "    df_occ = df.groupby(['guest_no'])['occupancy_rate'].median().reset_index()\n",
    "\n",
    "    med_price_occ_by_guests = go.Figure(data=[\n",
    "        go.Bar(name='Total Price', x=df_guests['guest_no'], y=df_guests['median_total_price'], yaxis='y', offsetgroup=1),\n",
    "        go.Bar(name='Occupancy Rate', x=df_occ['guest_no'], y=df_occ['occupancy_rate'], yaxis='y2', offsetgroup=2),\n",
    "    ],\n",
    "        layout={\n",
    "            'xaxis': {'title': '# of Guests'},\n",
    "            'yaxis': {'title': 'Total Price'},\n",
    "            'yaxis2': {'title': 'Occupancy Rate', 'overlaying': 'y', 'side': 'right'}\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Change the bar mode\n",
    "    med_price_occ_by_guests.update_layout(title_text='Median Price and Occupancy by # of Guests in '+location, barmode='group')\n",
    "    filename = \"newsletter_features/\"+location+\"_median_price_and_occ_by_guestno_june19.png\"\n",
    "    med_price_occ_by_guests.write_image(filename, engine='kaleido')\n",
    "    #miami_fig.show()\n",
    "\n",
    "def avg_30yrmort_by_guests(df, location: str):\n",
    "    df_guests_mort = df.groupby(['guest_no'])['avg_30_yr_mort'].median().reset_index()\n",
    "\n",
    "    avg_mort_by_guests_fig = go.Figure(data=[\n",
    "        go.Bar(name='Total Price', x=df_guests_mort['guest_no'], y=df_guests_mort['avg_30_yr_mort'])\n",
    "    ],\n",
    "        layout={\n",
    "            'xaxis': {'title': '# of Guests'},\n",
    "            'yaxis': {'title': 'Monthly Mortgage Cost ($)'},\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Change the bar mode\n",
    "    avg_mort_by_guests_fig.update_layout(title_text='Avg 30-Year Mortgage by # of Guests in '+location)\n",
    "    filename = \"newsletter_features/\"+location+\"_monthly_mortgage_by_guestno_june19.png\"\n",
    "    avg_mort_by_guests_fig.write_image(filename, engine='kaleido')\n",
    "    #miami_fig.show()\n",
    "\n",
    "\n",
    "def avg_roi_fig_generator(df, location: str, groupbycol='zipcode', filename_end=\"_zips_roi_fig_june19.png\"):\n",
    "    #df['zipcode'] = df.apply(lambda row: set_zipcode(row['lat'], row['lng']), axis=1)\n",
    "    zips_roi_df = df.groupby(groupbycol)[['median_ROI']].mean().reset_index()\n",
    "\n",
    "    zips_roi_fig = go.Figure(data=[\n",
    "        go.Bar(name='Display Price', x=zips_roi_df[groupbycol], y=zips_roi_df['median_ROI']),\n",
    "        ],\n",
    "        \n",
    "        layout={\n",
    "            'xaxis': {'title': groupbycol},\n",
    "            'yaxis': {'title': 'ROI (1 = 100%)'},\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Change the bar mode\n",
    "    zips_roi_fig.update_layout(title_text='Average ROI in '+location+' by '+groupbycol, barmode='stack')\n",
    "    filename = \"newsletter_features/\"+location+filename_end\n",
    "    zips_roi_fig.write_image(filename, engine='kaleido')\n",
    "    #zips_roi_fig.show()\n",
    "\n",
    "\n",
    "def pricing_fig_generator(df, location: str, groupbycol='zipcode', filename_end=\"_zips_cleaning_fig_june19.png\"):\n",
    "    #df['zipcode'] = df.apply(lambda row: set_zipcode(row['lat'], row['lng']), axis=1)\n",
    "\n",
    "    zips_cleaning_df = df.groupby([groupbycol])[['price','median_cleaning_fee','median_service_fee']].median().reset_index()\n",
    "\n",
    "    zips_cleaning_fig = go.Figure(data=[\n",
    "        go.Bar(name='Display Price', x=zips_cleaning_df[groupbycol], y=zips_cleaning_df['price']),\n",
    "        go.Bar(name='Cleaning Fee', x=zips_cleaning_df[groupbycol], y=zips_cleaning_df['median_cleaning_fee']),\n",
    "        go.Bar(name='Service Fee', x=zips_cleaning_df[groupbycol], y=zips_cleaning_df['median_service_fee']),\n",
    "    ],\n",
    "        layout={\n",
    "            'xaxis': {'title': groupbycol},\n",
    "            'yaxis': {'title': 'Total Price ($)'},\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Change the bar mode\n",
    "    zips_cleaning_fig.update_layout(title_text='Median Pricing in '+location+' by '+groupbycol, barmode='stack')\n",
    "    filename = \"newsletter_features/\"+location+filename_end\n",
    "    zips_cleaning_fig.write_image(filename, engine='kaleido')\n",
    "    #miami_zips_cleaning_fig.show()\n",
    "\n",
    "def roi_bubble_plot(df, filename_end=\"roi_bubble_fig_june19.png\"):\n",
    "    import plotly.express as px\n",
    "    #df['City'] = df.apply(lambda row: set_city(row['lat'], row['lng'], axis=1))\n",
    "    df_group = df.groupby(['City','State','zipcode','guest_no'])['avg_30_yr_mort','median_ROI'].mean().reset_index()\n",
    "\n",
    "    roi_bubble_fig = px.scatter(df_group, x=\"guest_no\", y=\"median_ROI\",\n",
    "                size=\"avg_30_yr_mort\", color=\"State\",\n",
    "                    hover_name=\"zipcode\")\n",
    "    \n",
    "    roi_bubble_fig.update_layout(title_text='ROI vs Guest Number, sized by the Avg Monthly Mortgage', xaxis=dict(title='Guest Number for Listing'), yaxis=dict(title='Average ROI (1 = 100%)'))\n",
    "    filename = \"newsletter_features/\"+filename_end\n",
    "    roi_bubble_fig.write_image(filename, engine='kaleido')\n",
    "    roi_bubble_fig.show()\n",
    "\n",
    "def listing_count_bubble_plot(df, filename_end=\"listing_count_bubble_fig_june19.png\"):\n",
    "    import plotly.express as px\n",
    "    #df['City'] = df.apply(lambda row: set_city(row['lat'], row['lng'], axis=1))\n",
    "    df_group = df.groupby(['City','State','zipcode','guest_no'])['id'].count().reset_index()\n",
    "\n",
    "    listing_count_bubble_fig = px.scatter(df_group, x=\"guest_no\", y=\"id\",\n",
    "                    color=\"State\",\n",
    "                    hover_name=\"zipcode\")\n",
    "    \n",
    "    listing_count_bubble_fig.update_layout(title_text='Listing Count vs Guest Number, sized by the Avg Monthly Mortgage', xaxis=dict(title='Guest Number for Listing'), yaxis=dict(title='# of Listings'))\n",
    "    filename = \"newsletter_features/\"+filename_end\n",
    "    listing_count_bubble_fig.write_image(filename, engine='kaleido')\n",
    "    listing_count_bubble_fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in listing data\n",
    "nc_dir = 'C:/Users/mattg/Desktop/Hobbies/airbnb_reports/bucket_data/listings/north_carolina'\n",
    "first_file = ''\n",
    "for file in os.listdir(nc_dir):\n",
    "    first_file = os.path.join(nc_dir,file)\n",
    "    break\n",
    "listing_data = pd.read_parquet(first_file)\n",
    "print(listing_data.shape)\n",
    "for file in os.listdir(nc_dir):\n",
    "    next_file = os.path.join(nc_dir,file)\n",
    "    if next_file != first_file:\n",
    "        next_listing = pd.read_parquet(next_file)\n",
    "        listing_data = listing_data.append(next_listing)\n",
    "print(listing_data.shape)\n",
    "\n",
    "ne_dir = 'C:/Users/mattg/Desktop/Hobbies/airbnb_reports/bucket_data/listings/vt_nh'\n",
    "for file in os.listdir(ne_dir):\n",
    "    next_file = os.path.join(ne_dir,file)\n",
    "    next_listing = pd.read_parquet(next_file)\n",
    "    listing_data = listing_data.append(next_listing)\n",
    "print(listing_data.shape)\n",
    "\n",
    "miami_dir = 'C:/Users/mattg/Desktop/Hobbies/airbnb_reports/bucket_data/listings/miami'\n",
    "for file in os.listdir(miami_dir):\n",
    "    next_file = os.path.join(miami_dir,file)\n",
    "    next_listing = pd.read_parquet(next_file)\n",
    "    listing_data = listing_data.append(next_listing)\n",
    "print(listing_data.shape)\n",
    "\n",
    "# Load in occupancy data\n",
    "occ_data = pd.read_parquet('C:/Users/mattg/Desktop/Hobbies/airbnb_reports/bucket_data/occupancy')\n",
    "\n",
    "# Load in price data\n",
    "price_data = pd.read_parquet('C:/Users/mattg/Desktop/Hobbies/airbnb_reports/bucket_data/prices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up listing_data\n",
    "conditions = [\n",
    "    listing_data['baths'].str.contains('shared', na=False),\n",
    "    listing_data['baths'].str.contains('Shared', na=False)\n",
    "]\n",
    "\n",
    "values = ['Shared', 'Shared']\n",
    "\n",
    "listing_data['baths_type'] = np.select(conditions, values, default='Private')\n",
    "\n",
    "conditions_loc = [\n",
    "    listing_data['top_lat'] > 35.5,\n",
    "    listing_data['top_lat'] < 28\n",
    "]\n",
    "\n",
    "values_loc = ['New England', 'Miami']\n",
    "\n",
    "listing_data['Region'] = np.select(conditions_loc, values_loc, default='Carolinas')\n",
    "\n",
    "\n",
    "conditions_halfbath = [\n",
    "    listing_data['baths'].str.contains('Half-bath', na=False),\n",
    "    listing_data['baths'].str.contains('Shared half-bath', na=False),\n",
    "    listing_data['baths'].str.contains('Private half-bath', na=False)\n",
    "]\n",
    "\n",
    "values_halfbath = [0.5,0.5,0.5]\n",
    "\n",
    "listing_data['baths'] = np.select(conditions_halfbath, values_halfbath, default=listing_data['baths'])\n",
    "\n",
    "listing_data['baths_no'] = listing_data['baths'].str.split(' ').str[0]\n",
    "listing_data['beds_no'] = listing_data['beds'].str.split(' ').str[0]\n",
    "listing_data['guest_no'] = listing_data['title'].str.split(' ').str[0]\n",
    "listing_data['guest_no'] = listing_data['guest_no'].astype('float')\n",
    "listing_data['id'] = listing_data['id'].astype('float64')\n",
    "listing_data['id'] = listing_data['id'].astype('str')\n",
    "listing_data['town'] = listing_data['town'].str.lower()\n",
    "listing_data = listing_data[listing_data.lat.isna() == False]\n",
    "\n",
    "# Clean up occ_data\n",
    "#occ_data['id'] = occ_data['id'].astype('int')\n",
    "occ_data['id'] = occ_data['id'].astype('str')\n",
    "\n",
    "# Clean up price_data\n",
    "#price_data['id'] = price_data['id'].astype('int')\n",
    "price_data['id'] = price_data['id'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_data_date = occ_data.groupby(['date'])['available'].apply(lambda row: np.sum(row)/len(row)).reset_index()\n",
    "\n",
    "occupancy_rate_fig = px.line(occ_data_date,\n",
    "        x=\"date\",\n",
    "        y=\"available\",\n",
    "        title=\"Occupancy Rate by Date\"\n",
    "    )\n",
    "\n",
    "filename = \"newsletter_features/occupancy_rate_line_fig_june19.png\"\n",
    "occupancy_rate_fig.write_image(filename, engine='kaleido')\n",
    "occupancy_rate_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_data_date = price_data.groupby(['check_in'])['cleaning_fee','service_fee','total_price'].apply(lambda row: np.sum(row)/len(row)).reset_index()\n",
    "\n",
    "# Create traces\n",
    "price_data_line_fig = go.Figure()\n",
    "price_data_line_fig.add_trace(go.Scatter(x=price_data_date['check_in'], y=price_data_date['cleaning_fee'],\n",
    "                    mode='lines',\n",
    "                    name='Cleaning Fee'))\n",
    "price_data_line_fig.add_trace(go.Scatter(x=price_data_date['check_in'], y=price_data_date['service_fee'],\n",
    "                    mode='lines',\n",
    "                    name='Service Fee'))\n",
    "price_data_line_fig.add_trace(go.Scatter(x=price_data_date['check_in'], y=price_data_date['total_price'],\n",
    "                    mode='lines', \n",
    "                    name='Total Price'))\n",
    "price_data_line_fig.update_layout(title_text=\"Pricing Data by Date\", xaxis_title='Date', yaxis_title='Price ($)')\n",
    "filename = \"newsletter_features/price_data_line_fig_june19.png\"\n",
    "price_data_line_fig.write_image(filename, engine='kaleido', width=2000, height=500)\n",
    "price_data_line_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_data_bar_fig = go.Figure(data=[\n",
    "    go.Bar(name='Cleaning Fee', x=price_data_date['check_in'], y=price_data_date['cleaning_fee']),\n",
    "    go.Bar(name='Service Fee', x=price_data_date['check_in'], y=price_data_date['service_fee']),\n",
    "    #go.Bar(name='Total Price', x=price_data_date['check_in'], y=price_data_date['total_price']),\n",
    "],\n",
    "    layout={\n",
    "        'xaxis': {'title': 'Date'},\n",
    "        'yaxis': {'title': 'Price ($)'},\n",
    "    }\n",
    ")\n",
    "\n",
    "# Change the bar mode\n",
    "price_data_bar_fig.update_layout(title_text='Pricing Data by Date', barmode='stack')\n",
    "filename = \"newsletter_features/price_data_bar_fig_june19.png\"\n",
    "price_data_bar_fig.write_image(filename, engine='kaleido')\n",
    "price_data_bar_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_data.to_csv('listings_june19.csv')\n",
    "#listing_data_static = pd.read_csv('listings_w_states.csv')\n",
    "start_time = time.time()\n",
    "listing_data['zipcode'] = listing_data.apply(lambda row: set_zipcode(row['lat'], row['lng']), axis=1)\n",
    "end_time = time.time()\n",
    "listing_data.to_csv('listings_w_zips_june19.csv')\n",
    "print('Time to run was ' + str(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_data = pd.read_csv('listings_w_zips_june19.csv')\n",
    "\n",
    "# home value by zipcode\n",
    "home_value_1bed = pd.read_csv('resource_data/zillow_zip_onebed.csv')\n",
    "home_value_2bed = pd.read_csv('resource_data/zillow_zip_twobed.csv')\n",
    "home_value_3bed = pd.read_csv('resource_data/zillow_zip_threebed.csv')\n",
    "home_value_4bed = pd.read_csv('resource_data/zillow_zip_fourbed.csv')\n",
    "home_value_5plusbed = pd.read_csv('resource_data/zillow_zip_fiveplusbed.csv')\n",
    "\n",
    "#home_value_1bed['RegionName'] = home_value_1bed['RegionName'].str.lower()\n",
    "home_value_1bed_reduced = home_value_1bed[['RegionName','City','Metro','CountyName','State','4/30/2022']]\n",
    "home_value_1bed_reduced['num_beds'] = 1\n",
    "\n",
    "#home_value_2bed['RegionName'] = home_value_2bed['RegionName'].str.lower()\n",
    "home_value_2bed_reduced = home_value_2bed[['RegionName','City','Metro','CountyName','State','4/30/2022']]\n",
    "home_value_2bed_reduced['num_beds'] = 2\n",
    "\n",
    "#home_value_3bed['RegionName'] = home_value_3bed['RegionName'].str.lower()\n",
    "home_value_3bed_reduced = home_value_3bed[['RegionName','City','Metro','CountyName','State','4/30/2022']]\n",
    "home_value_3bed_reduced['num_beds'] = 3\n",
    "\n",
    "#home_value_4bed['RegionName'] = home_value_4bed['RegionName'].str.lower()\n",
    "home_value_4bed_reduced = home_value_4bed[['RegionName','City','Metro','CountyName','State','4/30/2022']]\n",
    "home_value_4bed_reduced['num_beds'] = 4\n",
    "\n",
    "#home_value_5plusbed['RegionName'] = home_value_5plusbed['RegionName'].str.lower()\n",
    "home_value_5plusbed_reduced = home_value_5plusbed[['RegionName','City','Metro','CountyName','State','4/30/2022']]\n",
    "home_value_5plusbed_reduced['num_beds'] = 5\n",
    "\n",
    "home_values = home_value_1bed_reduced.append(home_value_2bed_reduced)\n",
    "home_values = home_values.append(home_value_3bed_reduced)\n",
    "home_values = home_values.append(home_value_4bed_reduced)\n",
    "home_values = home_values.append(home_value_5plusbed_reduced)\n",
    "\n",
    "home_values = home_values[['RegionName','City','Metro','CountyName','State','4/30/2022','num_beds']]\n",
    "home_values = home_values.drop_duplicates()\n",
    "\n",
    "home_values.to_csv('home_values_combined_june19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_data = pd.read_csv('listings_w_zips_june19.csv')\n",
    "listing_data = listing_data[listing_data['zipcode'].notna()]\n",
    "listing_data = listing_data[~listing_data['zipcode'].str.contains(':')]\n",
    "listing_data['zipcode'] = listing_data['zipcode'].astype('int')\n",
    "listing_data = listing_data.merge(home_values, how='inner', left_on=['zipcode','beds_no'], right_on=['RegionName','num_beds'])\n",
    "print(listing_data.shape)\n",
    "listing_data['avg_home_value'] = listing_data.apply(lambda row: set_avg_home_val_w_zip(home_values, row['zipcode'], row['beds_no']),axis=1)\n",
    "listing_data = listing_data[listing_data['avg_home_value'].notna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_data['id'] = listing_data['id'].astype('str')\n",
    "\n",
    "occ_rate = occ_data.groupby('id')['available'].apply(lambda row: np.sum(row)/len(row)).reset_index()\n",
    "occ_rate['id'] = occ_rate['id'].astype('str')\n",
    "combined_data = listing_data.merge(occ_rate, on = 'id')\n",
    "combined_data.rename(columns = {'available':'occupancy_rate'}, inplace = True)\n",
    "\n",
    "cleaning_fee = price_data.groupby(['id'])['cleaning_fee'].median().reset_index()\n",
    "cleaning_fee.rename(columns = {'cleaning_fee':'median_cleaning_fee'}, inplace = True)\n",
    "service_fee = price_data.groupby(['id'])['service_fee'].median().reset_index()\n",
    "service_fee.rename(columns = {'service_fee':'median_service_fee'}, inplace = True)\n",
    "combined_data = combined_data.merge(cleaning_fee, on='id')\n",
    "combined_data = combined_data.merge(service_fee, on='id')\n",
    "combined_data['median_total_price'] = combined_data['price'] + combined_data['median_cleaning_fee'] + combined_data['median_service_fee']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding avg mortgage and median ROI\n",
    "combined_data['avg_30_yr_mort'] = combined_data.apply(lambda row: calculate_mortgage(row['avg_home_value'], 5, 30), axis=1)\n",
    "combined_data['monthly_maintenance'] = combined_data.apply(lambda row: calculate_monthly_maintenance(row['avg_home_value']), axis=1)\n",
    "combined_data['monthly_tax'] = combined_data.apply(lambda row: calculate_monthly_taxes(row['avg_home_value'], row['State']), axis=1)\n",
    "combined_data['median_ROI'] = combined_data.apply(lambda row: calculate_roi(row['median_total_price'], row['occupancy_rate'], row['avg_30_yr_mort'], row['monthly_maintenance'], row['monthly_tax']), axis=1)\n",
    "combined_data['zipcode'] = combined_data['zipcode'].astype('str')\n",
    "combined_data = combined_data.to_csv('post_mort_and_roi_calcs_june19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv('post_mort_and_roi_calcs_june19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "roi_subplots = make_subplots(rows=3, cols=2)\n",
    "\n",
    "combined_data_vt = combined_data[(combined_data['State'] == 'VT')]\n",
    "combined_data_nh = combined_data[(combined_data['State'] == 'NH')]\n",
    "combined_data_nc = combined_data[(combined_data['State'] == 'NC')]\n",
    "combined_data_sc = combined_data[(combined_data['State'] == 'SC')]\n",
    "combined_data_fl = combined_data[(combined_data['State'] == 'FL')]\n",
    "combined_data_me = combined_data[(combined_data['State'] == 'ME')]\n",
    "\n",
    "combined_data_vt_mean_roi = combined_data_vt.groupby(['town'])['median_ROI'].mean().reset_index()\n",
    "combined_data_nh_mean_roi = combined_data_nh.groupby(['town'])['median_ROI'].mean().reset_index()\n",
    "combined_data_nc_mean_roi = combined_data_nc.groupby(['town'])['median_ROI'].mean().reset_index()\n",
    "combined_data_sc_mean_roi = combined_data_sc.groupby(['town'])['median_ROI'].mean().reset_index()\n",
    "combined_data_fl_mean_roi = combined_data_fl.groupby(['town'])['median_ROI'].mean().reset_index()\n",
    "combined_data_me_mean_roi = combined_data_me.groupby(['town'])['median_ROI'].mean().reset_index()\n",
    "\n",
    "\n",
    "roi_subplots.append_trace(\n",
    "    go.Bar(x=combined_data_vt_mean_roi['town'],\n",
    "    y=combined_data_vt_mean_roi['median_ROI'], name=\"VT\"\n",
    "), row=1, col=1)\n",
    "\n",
    "roi_subplots.append_trace(go.Bar(\n",
    "    x=combined_data_nh_mean_roi['town'],\n",
    "    y=combined_data_nh_mean_roi['median_ROI'], name=\"NH\"\n",
    "), row=1, col=2)\n",
    "\n",
    "roi_subplots.append_trace(go.Bar(\n",
    "    x=combined_data_nc_mean_roi['town'],\n",
    "    y=combined_data_nc_mean_roi['median_ROI'], name=\"NC\"\n",
    "), row=2, col=1)\n",
    "\n",
    "roi_subplots.append_trace(go.Bar(\n",
    "    x=combined_data_sc_mean_roi['town'],\n",
    "    y=combined_data_sc_mean_roi['median_ROI'], name=\"SC\"\n",
    "), row=2, col=2)\n",
    "\n",
    "roi_subplots.append_trace(go.Bar(\n",
    "    x=combined_data_fl_mean_roi['town'],\n",
    "    y=combined_data_fl_mean_roi['median_ROI'], name=\"FL\"\n",
    "), row=3, col=1)\n",
    "\n",
    "roi_subplots.append_trace(go.Bar(\n",
    "    x=combined_data_me_mean_roi['town'],\n",
    "    y=combined_data_me_mean_roi['median_ROI'], name=\"ME\"\n",
    "), row=3, col=2)\n",
    "\n",
    "\n",
    "roi_subplots.update_layout(height = 1100, title_text=\"Mean ROI for Cities in each State\", barmode='group')\n",
    "filename = \"newsletter_features/mean_roi_for_cities_by_state_june19.png\"\n",
    "roi_subplots.write_image(filename, engine='kaleido')\n",
    "\n",
    "roi_subplots.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_bubble_plot(combined_data)\n",
    "listing_count_bubble_plot(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state_id in combined_data.State.unique():\n",
    "    state_combined_data = combined_data[(combined_data['State'] == state_id)]\n",
    "    state_combined_data['zipcode'] = state_combined_data['zipcode'].astype('str')\n",
    "    state_combined_data['RegionName'] = state_combined_data['RegionName'].astype('str')\n",
    "    med_price_occ_by_guests(state_combined_data, location=state_id)\n",
    "    avg_roi_fig_generator(state_combined_data, location=state_id)\n",
    "    pricing_fig_generator(state_combined_data, location=state_id)\n",
    "    avg_roi_fig_generator(state_combined_data, location=state_id,groupbycol='City',filename_end=\"_cities_roi_fig_june19.png\")\n",
    "    pricing_fig_generator(state_combined_data, location=state_id,groupbycol='City',filename_end=\"_cities_cleaning_fig_june19.png\")\n",
    "    avg_30yrmort_by_guests(state_combined_data, location=state_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing w price table for json testing\n",
    "listing_w_zips = pd.read_csv('listings_w_zips_june19.csv')\n",
    "listing_w_zips = listing_w_zips[['id','zipcode','guest_no']]\n",
    "\n",
    "price_data_to_merge = pd.read_csv('price_trends_for_map.csv')\n",
    "price_data_to_merge = price_data_to_merge[['id','cleaning_fee_x','service_fee_x','total_price_x']]\n",
    "price_data_to_merge['display_price_x'] = price_data_to_merge['total_price_x'] - price_data_to_merge['cleaning_fee_x'] - price_data_to_merge['service_fee_x']\n",
    "#\n",
    "listing_w_zips_price = listing_w_zips.merge(price_data_to_merge, how='inner', on='id')\n",
    "listing_w_zips_price = listing_w_zips_price.rename(columns={\"guest_no\": \"Guest Number\", \"display_price_x\": \"Display Price\", \"cleaning_fee_x\": \"Cleaning Fee\", \"service_fee_x\": \"Service Fee\", \"total_price_x\": \"Total Price\"})\n",
    "#df_guests = listing_w_zips_price.groupby(['guest_no','zipcode'])[['Display Price', 'Cleaning Fee', 'Service Fee', 'Total Price']].median().reset_index() #Might want to group by both guest_no and zipcode\n",
    "df_guests_price = listing_w_zips_price.groupby(['Guest Number'])[['Display Price', 'Cleaning Fee', 'Service Fee', 'Total Price']].median().reset_index()\n",
    "df_guests_price = df_guests_price.round({'Guest Number': 0, 'Display Price': 2, 'Cleaning Fee': 2, 'Service Fee': 2, 'Total Price': 2})\n",
    "df_guests_price = df_guests_price.dropna()\n",
    "df_guests_price.to_csv('price_by_guest_no.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing w occupancy rate table for json testing\n",
    "listing_w_zips = pd.read_csv('listings_w_zips_june19.csv')\n",
    "listing_w_zips = listing_w_zips[['id','zipcode','guest_no']]\n",
    "\n",
    "occ_data_to_merge = pd.read_csv('occ_trends_wloc_zip_for_table.csv')\n",
    "occ_data_to_merge = occ_data_to_merge[['id','available_x']]\n",
    "\n",
    "listing_w_zips_occ = listing_w_zips.merge(occ_data_to_merge, how='inner', on='id')\n",
    "listing_w_zips_occ = listing_w_zips_occ.rename(columns={\"guest_no\": \"Guest Number\", \"available_x\": \"Occupancy Rate\"})\n",
    "#df_guests = listing_w_zips_price.groupby(['guest_no','zipcode'])[['Display Price', 'Cleaning Fee', 'Service Fee', 'Total Price']].median().reset_index() #Might want to group by both guest_no and zipcode\n",
    "df_guests_occ = listing_w_zips_occ.groupby(['Guest Number'])['Occupancy Rate'].median().reset_index()\n",
    "df_guests_occ = df_guests_occ.round({'Guest Number': 0, 'Occupancy Rate': 2})\n",
    "df_guests_occ = df_guests_occ.dropna()\n",
    "df_guests_occ.to_csv('occ_rate_by_guest_no.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing other options for plotting pricing with occupancy\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "trace1= px.bar(df_guests_price, x='Guest Number', y=['Display Price','Cleaning Fee', 'Service Fee'], title=\"first trace\")\n",
    "\n",
    "fig.add_trace(trace1.data[0])\n",
    "fig.add_trace(trace1.data[1])\n",
    "fig.add_trace(trace1.data[2])\n",
    "fig.update_layout(title_text='Median Pricing Breakdown by Guest Number', barmode='stack')\n",
    "fig.update_xaxes(title='Guest Number')\n",
    "fig.update_yaxes(title='Price ($)')\n",
    "\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8cda3f1edda61d067a8dccfe73833b0b57e2a1d4ac0e36527d0cd620f4d2a66c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
